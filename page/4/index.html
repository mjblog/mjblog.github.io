<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>mjblog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="mjblog">
<meta property="og:url" content="http://mjblog.github.io/page/4/index.html">
<meta property="og:site_name" content="mjblog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Ma Jiang">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="mjblog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  

<meta name="generator" content="Hexo 4.2.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">mjblog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://mjblog.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-llvm_tr3_codegen" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/02/12/llvm_tr3_codegen/" class="article-date">
  <time datetime="2020-02-12T03:18:13.000Z" itemprop="datePublished">2020-02-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/12/llvm_tr3_codegen/">Kaleidoscope LLVM-IR codegen</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="学习内容"><a href="#学习内容" class="headerlink" title="学习内容"></a>学习内容</h2><p>完成对 <a href="https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.html" target="_blank" rel="noopener">https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl03.html</a> 的学习。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>看懂原网页后，实现同样的功能，补充测试。<br>实现时需要做如下改进：<br>将codegen过程从AST结构中剥离。编写一个codegenerator类，llvm-ir codegen作为该类的子类实现原示例的功能。为后续提供codegen到其他IR的扩展留下空间。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>1 clang 是如何实现AST到LLVM-IR的codegen<br>2 玩具实现和clang的实现之间有没有实质性的区别<br>3 是否能以较低的代价实现向方舟编译器的Maple-IR输出</p>
<h2 id="进展"><a href="#进展" class="headerlink" title="进展"></a>进展</h2><p>实现了原示例的全部功能。<br>考虑到单元测试效率较低，暂时尚未实现。后续可以考虑接入LLVM的测试框架。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>使用了code_generator这个模板虚基类来表达了处理Kaleidoscope玩具语言AST所需的功能接口。全局的入口只有function和prototype，理论上其实提供两个对应的gen函数就可以了。但是从完整性上考虑，其余的AST类型处理也最好做出约束，所以也一并写到了父类中。如下所示:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> VAL_PTR&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">code_generator</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">virtual</span> ~code_generator()&#123;&#125;;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">gen_function</span><span class="params">(<span class="keyword">const</span> function_ast* func)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">gen_prototype</span><span class="params">(<span class="keyword">const</span> prototype_ast* proto)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> VAL_PTR <span class="title">build_expr</span><span class="params">(<span class="keyword">const</span> expr_ast* expr)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> VAL_PTR <span class="title">build_call</span><span class="params">(<span class="keyword">const</span> call_ast* callee)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> VAL_PTR <span class="title">build_number</span><span class="params">(<span class="keyword">const</span> number_ast* num)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> VAL_PTR <span class="title">build_variable</span><span class="params">(<span class="keyword">const</span> variable_ast* var)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> VAL_PTR <span class="title">build_binary_op</span><span class="params">(<span class="keyword">const</span> binary_operator_ast* var)</span> </span>= <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">codegen</span><span class="params">(<span class="keyword">const</span> <span class="keyword">ast_vector_t</span>&amp; global_vec)</span> </span>;  <span class="comment">//唯一的数据输入，使用AST的vector</span></span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">print_IR</span><span class="params">()</span> </span>= <span class="number">0</span>;    <span class="comment">//唯一的数据输出，直接把生成的IR打印到stdin</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>针对LLVM-IR，参考原示例实现了基本相同的IR生成步骤。<br>主要的差异点包括：<br>1 去掉了JIT特性所需的全局expr处理；考虑学习方向是传统编译器架构，这个JIT特性会干扰到后续支持全局变量等特性，所以去掉。<br>2 将原实现基于AST的codegen转换为了独立的codegen框架，后续实现新的codegen会更容易(但是考虑到工作量和复杂度，没有实现vistor模式，两种codegen中一定会出现重复的AST访问模式。这样的模式确实是由AST来固化更好，参考clang对比中的相关内容)。</p>
<h3 id="clang对比"><a href="#clang对比" class="headerlink" title="clang对比"></a>clang对比</h3><p>1 clang 是如何实现AST到LLVM-IR的codegen<br>clang在lib/CodeGen实现了相关的功能。<br>在实现codegen功能上，代码流程和玩具实现没有本质区别。<br>都是遍历自己的AST，在这个过程中调用LLVM提供的核心类Module、Function、Builder来生成LLVM的IR。</p>
<p>2 玩具实现和clang的实现之间有没有实质性的区别<br>从调用LLVM的接口这个角度看没有实质性区别。<br>但是clang大量实现了Vistor模式，如AST/StmtVisitor.h、AST/RecursiveASTVisitor.h等。这些Visitor很好地将AST的固有访问模式固化下来，这样不同的任务（如print、codegen和evaluate等）就可以只提供针对具体AST结构的回调实现，而复用访问AST的骨架代码。<br>例如当前这个codegen的任务，它对AST的访问模式就是针对每一个函数递归的访问了所有AST节点。只要对每一种AST提供对应的visit代码就可以了。<br>例如function的visit就可以写成（如下模板），LLVM-IR生成器(作为下面的subclass)和MAPLE-IR生成器各自提供visit_prototype等visit接口就可以了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">check_muldef();</span><br><span class="line">subclass::visit_prototype(func-&gt;getproto());</span><br><span class="line">prepare_arg_map();</span><br><span class="line">subclass::visit_func_body(func-&gt;get_body());</span><br></pre></td></tr></table></figure>
<h3 id="方舟IR输出"><a href="#方舟IR输出" class="headerlink" title="方舟IR输出"></a>方舟IR输出</h3><p>方舟的实现也提供了类似的build函数，可参考mir_builder.h。<br>应该能以相似的方式（以及成本）从AST直接build出MAPLE-IR。<br>具体还待确认和核实。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mjblog.github.io/2020/02/12/llvm_tr3_codegen/" data-id="cknykihl9000sotfa2nh61y5z" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLVM-STUDY/" rel="tag">LLVM_STUDY</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-llvm_tr2_ast" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/24/llvm_tr2_ast/" class="article-date">
  <time datetime="2020-01-23T16:36:05.000Z" itemprop="datePublished">2020-01-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/24/llvm_tr2_ast/">Kaleidoscope ast</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="学习内容"><a href="#学习内容" class="headerlink" title="学习内容"></a>学习内容</h2><p>完成对<a href="https://github.com/zy445566/llvm-guide-zh/tree/master/Chapter02" target="_blank" rel="noopener">https://github.com/zy445566/llvm-guide-zh/tree/master/Chapter02</a><br>和<br><a href="https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.html" target="_blank" rel="noopener">https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.html</a><br>的学习。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>看懂原网页后，实现同样的功能，补充测试。<br>实现时需要做如下改进：<br>1 作为纯粹的前端，至少在生成LLVM-IR前不应该依赖llvm的任何代码。将所有的llvm::make_unique 改为 std::make_unique(C++11中没有这个接口所以llvm自己实现了，C++14已经有了；最新的LLVM代码也已经完成了向std的切换)<br>2 将parser作为class封装起来<br>3 日志输出的封装<br>4 基本功能测试</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>clang 是如何实现AST的构建<br>玩具实现和clang的实现之间有没有实质性的区别</p>
<h2 id="进展"><a href="#进展" class="headerlink" title="进展"></a>进展</h2><p>完成了示例parser的实现，并添加了对应的测试用例</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>除了完成了原示例外和前面计划的改进外，实现过程中还新增了一些改进，包括：<br>1 为每一个ast添加了type类型，便于管理ast指针<br>2 将每一个全局ast存入了统一的vector中，便于后续读取处理<br>3 为各个ast的内部接口添加了访问接口，以便读出数据进行测试<br>4 为所有的prototype提供了全局hash表，为后续call的一致性检查提供了便利<br>5 改进了原示例对toplevel expr的处理逻辑，将这些expr推入2步提供的vector中管理，不再放入一个匿名函数中（以避免重名等问题）<br>6 严格分层，parser不直接读取原始的char，其全部输入都来自lexer给出的token<br>7 小幅改进binary_op的相关解析流程，将原有流程中 op优先级和binary表达式结束 混合判断的情况做了拆分，逻辑上更易理解</p>
<h3 id="clang对比"><a href="#clang对比" class="headerlink" title="clang对比"></a>clang对比</h3><p>实现后，查看了clang的代码。<br>clang的parser基本解析流程和玩具示例的没有实质上的区别(注意到clang的parser也是处理token，不直接读取char)，尤其是binary_op的解析。<br>clang的lib/Parse/ParseExpr.cpp的ParseRHSOfBinaryExpression和示例中的parse_binary_expr基本逻辑是完全一样的。<br>阅读clang代码，发现了一些clang实现可借鉴的地方：<br>1 使用  using定义专有类型，可以使得代码更简洁</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> ExprResult = ActionResult&lt;Expr *&gt;;</span><br></pre></td></tr></table></figure>
<p>2 使用class内的模板函数自动完成指针类型的转换，可以使代码更简洁</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> PtrT&gt; <span class="function">PtrT <span class="title">getPtrAs</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">get</span>();</span><br></pre></td></tr></table></figure>
<p>3 定制测试框架设计（dump出文本+模式匹配），测试用例开发效率确实远高于直接使用gtest等通用单元测试框架</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mjblog.github.io/2020/01/24/llvm_tr2_ast/" data-id="cknykihl5000potfa31j80jql" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLVM-STUDY/" rel="tag">LLVM_STUDY</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-deep_learning" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/19/deep_learning/" class="article-date">
  <time datetime="2020-01-19T03:13:37.000Z" itemprop="datePublished">2020-01-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/19/deep_learning/">python深度学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="环境问题总结"><a href="#环境问题总结" class="headerlink" title="环境问题总结"></a>环境问题总结</h2><h3 id="启动keras示例，python3-examples-mnist-cnn-py"><a href="#启动keras示例，python3-examples-mnist-cnn-py" class="headerlink" title="启动keras示例，python3 examples/mnist_cnn.py"></a>启动keras示例，python3 examples/mnist_cnn.py</h3><p>找不到cuda相关的库。原因是tensorflow不支持10.2版本的cuda，安装10.0版本的cuda并添加库的搜索目录后解决（修改ld.conf后运行ldconfig）。<br>NVIDIA的驱动仍然可以使用最新的版本。</p>
<h3 id="启动keras示例，python3-examples-mnist-cnn-py-1"><a href="#启动keras示例，python3-examples-mnist-cnn-py-1" class="headerlink" title="启动keras示例，python3 examples/mnist_cnn.py"></a>启动keras示例，python3 examples/mnist_cnn.py</h3><p>遇到显卡无法正确使用的问题(无法分配内存)，可以在代码的头部使用添加如下片段解决。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.compat.v1 <span class="keyword">import</span> ConfigProto</span><br><span class="line"><span class="keyword">from</span> tensorflow.compat.v1 <span class="keyword">import</span> InteractiveSession</span><br><span class="line"></span><br><span class="line">config = ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="literal">True</span></span><br><span class="line">session = InteractiveSession(config=config)</span><br></pre></td></tr></table></figure>

<h3 id="遇到tensorflow报错Unknown-Failed-to-get-convolution-algorithm-This-is-probably-because-cuDNN-failed-to-initialize"><a href="#遇到tensorflow报错Unknown-Failed-to-get-convolution-algorithm-This-is-probably-because-cuDNN-failed-to-initialize" class="headerlink" title="遇到tensorflow报错Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize"></a>遇到tensorflow报错Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize</h3><p>重启后解决，可能和休眠的处理不好有关系。<br>使用notebook的时候睡眠，遇到了两次休眠后无法唤醒的问题。</p>
<h2 id="实验问题"><a href="#实验问题" class="headerlink" title="实验问题"></a>实验问题</h2><h3 id="5-3-1无法复现书中的96-精度"><a href="#5-3-1无法复现书中的96-精度" class="headerlink" title="5.3.1无法复现书中的96%精度"></a>5.3.1无法复现书中的96%精度</h3><h4 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h4><p>使用书中附带的notebook，在执行快速特征提取时，可以获得预期的90%精度。<br>但是使用数据增强后的程序，仍然也只能达到90%的精度。</p>
<h4 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h4><p>反复核对了代码，数据集，然后重新执行了多次仍然只有90%的精度。<br>使用goolge搜索using-a-pretrained-convnet，可以找到<a href="https://github.com/fchollet/deep-learning-with-python-notebooks/issues/21。" target="_blank" rel="noopener">https://github.com/fchollet/deep-learning-with-python-notebooks/issues/21。</a><br>阅读其中的讨论，最终可以在<a href="https://forums.manning.com/posts/list/42880.page" target="_blank" rel="noopener">https://forums.manning.com/posts/list/42880.page</a> 中找到较为完整的解释。<br>When I run the code given in the book, my validation accuracy plateaus around 0.90, exactly like the original poster described. I think the problem is that in the book’s code, the images are being read in from disk as numpy arrays of float32 values in the range [0.0, 1.0], due to the keyword argument [tt]rescale=1./255[/tt] in the ImageDataGenerator constructors. These images are then automatically fed directly to the VGG16 convolutional base when the model’s [tt]fit_generator[/tt] method is called.</p>
<p>However, the original VGG16 network was trained on images that were preprocessed by zero-centering each color channel with respect to the ImageNet database. In Keras, there is a function available (in keras.applications.vgg16) that does this transformation, called [tt]preprocess_input[/tt]. In fact, if you test the full pretrained VGG16 network by itself, you will find that in order to get accurate classification results, you must call [tt]preprocess_input[/tt] first before calling the [tt]predict[/tt] method. Furthermore, [tt]preprocess_input[/tt] must be called on images of float32 values in the range [0., 255.], not [0., 1.].</p>
<p>So to summarize, there are two problems with the book’s example: first, it uses images with values in the range [0., 1.], and second, it does not call [tt]preprocess_input[/tt] before feeding the images to the VGG16 base.<br>问题的本质是本书作者在这一节犯了一个低级错误，在使用VGG16这个预训练模型时，再次训练时送入的数据没有按照VGG16模型的要求进行预处理。同时，作者使用的keras老版本有一个bug，conv_base.trainable = False这句没有生效，所以作者实际上是对整个VGG16模型做了再次完整的训练，网络自动适配了新的值域，精度仍然达到了96%。</p>
<p>按照上面的建议修改notebook中的代码如下，确实能获得预期的96%精度。<br>使用    preprocessing_function=keras.applications.vgg16.preprocess_input和preprocessing_function=preprocess_input 没有实质性的差异。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    <span class="comment">#rescale=1./255,</span></span><br><span class="line"> <span class="comment">#    preprocessing_function=preprocess_input,</span></span><br><span class="line">    preprocessing_function=keras.applications.vgg16.preprocess_input,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#test_datagen = ImageDataGenerator(rescale=1./255)</span></span><br><span class="line">test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)</span><br></pre></td></tr></table></figure>
<p>并且，按照后续讨论的结果，对使用快速特征提取的代码也做正确的预处理，确实也能很快达到96%的精度。后面网友的讨论应该是正确的，对于这个问题来说，数据增强并不是必要的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"></span><br><span class="line"><span class="comment">#datagen = ImageDataGenerator(rescale=1./255)</span></span><br><span class="line">datagen = ImageDataGenerator(preprocessing_function=preprocess_input)</span><br></pre></td></tr></table></figure>
<h4 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h4><p>&emsp;<font color=red>输入数据的准备极端重要</font>（类型正确，数值范围正确，统一的预处理方法），可能严重影响模型的精度；<br>&emsp;<font color=red>深度网络自动学习特征表示的能力确实很强</font>，一个使用0<del>255输入值域预训练的网络，只要不冻结它的weight，即使使用0</del>1值域的输入样本重新训练，也仍然能保留其绝大部分的分类能力。<font color=red>网络自动适应了输入值域的失配问题</font>；<br>&emsp;<font color=red>深度学习确实是实践重于理论，大神也可能犯低级错误</font>。本文作者就犯了输入数据准备的错误。由于低版本keras的bug（froenzen不生效，实际上预训练的网络被完全重新训练）加上深度网络的强大自动学习能力，作者使用低版本的keras即使输入了错误的值域数据也仍然获得了96%的高精度。由于这一结果符合预期，作者忽略了这个错误。</p>
<h3 id="第6章学习的问题记录"><a href="#第6章学习的问题记录" class="headerlink" title="第6章学习的问题记录"></a>第6章学习的问题记录</h3><p>6.1.3 冻结与不冻结词嵌入层的对比<br>作为练习，6.1.3节中提到冻结词嵌入层和不冻结词嵌入层，针对不同的训练样本数量进行性能比较。<br>实际操作时，因为操作错误没有对训练过的模型进行清零。多次训练时，发现冻结词嵌入层时，如果扩大过训练样本数量，然后再降低样本数量再训练，仍然能保持很高的精度。本次练习中，10000个样本，如果用数千个样本训练过，再用500个样本训练网络，仍然可以保持很高的精度95%。而不冻结词嵌入层，用小样本量再训练，无法维持高精度。应该是反向传播破坏了嵌入层的正确表示。</p>
<p>LSTM训练速度问题<br>LSTM训练速度很慢，并且GPU的利用率只能到35%。后续应该看看这里的性能瓶颈。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mjblog.github.io/2020/01/19/deep_learning/" data-id="cknykihky0009otfack5xh0ie" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/" rel="tag">AI</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-llvm_tr1_lexer" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/01/14/llvm_tr1_lexer/" class="article-date">
  <time datetime="2020-01-14T07:04:23.000Z" itemprop="datePublished">2020-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/14/llvm_tr1_lexer/">Kaleidoscope lexer</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="学习内容"><a href="#学习内容" class="headerlink" title="学习内容"></a>学习内容</h2><p>完成对<a href="https://github.com/zy445566/llvm-guide-zh/blob/master/Chapter01/README.md" target="_blank" rel="noopener">https://github.com/zy445566/llvm-guide-zh/blob/master/Chapter01/README.md</a> 和<br><a href="https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.html" target="_blank" rel="noopener">https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.html</a><br>的学习。</p>
<h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>看懂原网页后，实现同样的功能。<br>实现时需要做如下改进：<br>使用class将lexer封装起来，不使用全局变量<br>使用stream来抽象输入，使得lexer能支持stdin和文件两种方式作为输入。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>clang 是如何实现lexer，如何取出和记录token的<br>玩具实现和clang的实现之间有没有实质性的区别</p>
<h2 id="进展"><a href="#进展" class="headerlink" title="进展"></a>进展</h2><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>参考原有实现，做了如下一些改进：<br>使用了lexer 类来封装原示例中的全局数据；<br>使用基于istream的抽象，使得lexer可以支持文件和stdin两种输入；<br>使用独立的token 类，逻辑更清晰（我们使用string 存放token对应的字符串比较低效，clang是直接使用一个char *ptr+ size来给出这个信息，避免了存放冗余的信息 ，占用内存少速度也更快）。</p>
<h3 id="clang对比"><a href="#clang对比" class="headerlink" title="clang对比"></a>clang对比</h3><p>总体来说，clang的lexer核心逻辑和我们的学习示例一致。<br>lexer部分给出的token，最关键的就是Kind(相当于我们的type)和 PtrData (相当于我们的raw_str)<br>include/clang/Lex 中可以作为分析入口。<br>lexer.h中含有各类主要问题的分析入手点。其中FormTokenWithChars函数比较典型。</p>
<p>由于clang需要进行考虑预处理（包括include、marcro等），记录token在源代码中的位置等，其lexer的实现要复杂很多。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://mjblog.github.io/2020/01/14/llvm_tr1_lexer/" data-id="cknykihl4000lotfagoon3s5z" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LLVM-STUDY/" rel="tag">LLVM_STUDY</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; __(&#39;prev&#39;)</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ANDROID/" rel="tag">ANDROID</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Android/" rel="tag">Android</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GRAALVM/" rel="tag">GRAALVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IDE/" rel="tag">IDE</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLVM-STUDY/" rel="tag">LLVM_STUDY</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/env/" rel="tag">env</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/ANDROID/" style="font-size: 16.67px;">ANDROID</a> <a href="/tags/Android/" style="font-size: 13.33px;">Android</a> <a href="/tags/GRAALVM/" style="font-size: 16.67px;">GRAALVM</a> <a href="/tags/IDE/" style="font-size: 10px;">IDE</a> <a href="/tags/LLVM-STUDY/" style="font-size: 20px;">LLVM_STUDY</a> <a href="/tags/env/" style="font-size: 10px;">env</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">五月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">四月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/06/17/react_native_profile/">react native 手势动画性能分析</a>
          </li>
        
          <li>
            <a href="/2021/05/28/android_rust_dev/">Android Rust 接入</a>
          </li>
        
          <li>
            <a href="/2021/04/27/node_js_native_plugin_ana/">nodejs native 插件调研</a>
          </li>
        
          <li>
            <a href="/2021/03/26/graalvm_observing_compilations/">graalvm 编译过程分析工具</a>
          </li>
        
          <li>
            <a href="/2021/03/10/android_startup_trace/">app_process 初始化阶段trace</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 Ma Jiang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div>
</body>
</html>